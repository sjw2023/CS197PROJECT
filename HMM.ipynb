{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are total 3914 sentence in the dataset.\n",
      "There are 3131 training data.\n",
      "There are 783 testing data.\n",
      "There are 80159 training word.\n",
      "There are 20517 testing word.\n"
     ]
    }
   ],
   "source": [
    "# We use treebanck corpus as our dataset.\n",
    "data = list(nltk.corpus.treebank.tagged_sents(tagset='universal'))\n",
    "print(\"There are total %s sentence in the dataset.\" %len(data))\n",
    "\n",
    "#shuffle the data\n",
    "random.shuffle(data)\n",
    "random.seed(0)\n",
    "\n",
    "#splite the data, change N to change training data size.\n",
    "N = 0.80\n",
    "train_data = data[: math.floor(len(data)*N)]\n",
    "test_data = data[math.floor(len(data)*N): ]\n",
    "\n",
    "#train_test_split(nltk_data,train_size=N,test_size=1-N,random_state = 101)\n",
    "print(\"There are %s training data.\" %len(train_data))\n",
    "print(\"There are %s testing data.\" %len(test_data))\n",
    "\n",
    "#split training sentence and test sentence into single word.\n",
    "train_split = [word for sentence in train_data for word in sentence]\n",
    "test_split = [word for sentence in test_data for word in sentence]\n",
    "\n",
    "print(\"There are %s training word.\" %len(train_split))\n",
    "print(\"There are %s testing word.\" %len(test_split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transition Probability for specific pair of tags\n",
    "def transition(front_tag, back_tag, train_split = train_split):\n",
    "    countfront = 0\n",
    "    countfollow = 0\n",
    "    for index, pair in enumerate(train_split):\n",
    "        if pair[1] == front_tag:\n",
    "            countfront += 1\n",
    "            if  index+1 != len(train_split) and train_split[index+1][1] == back_tag:\n",
    "                countfollow += 1\n",
    "                \n",
    "    trans_prob = countfollow/countfront\n",
    "    return trans_prob\n",
    "\n",
    "\n",
    "# Emission Probability for specific word \n",
    "def Emission(word, tag, train_splite = train_split):\n",
    "    num_word = len([st[0] for st in train_splite if st[0] == word and st[1] ==tag])\n",
    "    num_tag = len([st for st in train_split if st[1] == tag])\n",
    "    return num_word/num_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>.</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>ADP</th>\n",
       "      <th>ADV</th>\n",
       "      <th>CONJ</th>\n",
       "      <th>DET</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>NUM</th>\n",
       "      <th>PRON</th>\n",
       "      <th>PRT</th>\n",
       "      <th>VERB</th>\n",
       "      <th>X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>0.095412</td>\n",
       "      <td>0.044268</td>\n",
       "      <td>0.090792</td>\n",
       "      <td>0.052326</td>\n",
       "      <td>0.059847</td>\n",
       "      <td>0.174815</td>\n",
       "      <td>0.215322</td>\n",
       "      <td>0.078973</td>\n",
       "      <td>0.065757</td>\n",
       "      <td>0.002579</td>\n",
       "      <td>0.091759</td>\n",
       "      <td>0.028043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ADJ</td>\n",
       "      <td>0.064415</td>\n",
       "      <td>0.065977</td>\n",
       "      <td>0.079641</td>\n",
       "      <td>0.003709</td>\n",
       "      <td>0.016787</td>\n",
       "      <td>0.005661</td>\n",
       "      <td>0.699395</td>\n",
       "      <td>0.020301</td>\n",
       "      <td>0.000781</td>\n",
       "      <td>0.011321</td>\n",
       "      <td>0.011517</td>\n",
       "      <td>0.020496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ADP</td>\n",
       "      <td>0.039501</td>\n",
       "      <td>0.103338</td>\n",
       "      <td>0.016947</td>\n",
       "      <td>0.013507</td>\n",
       "      <td>0.000892</td>\n",
       "      <td>0.330912</td>\n",
       "      <td>0.322885</td>\n",
       "      <td>0.059760</td>\n",
       "      <td>0.069062</td>\n",
       "      <td>0.001656</td>\n",
       "      <td>0.008410</td>\n",
       "      <td>0.033129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ADV</td>\n",
       "      <td>0.135315</td>\n",
       "      <td>0.134142</td>\n",
       "      <td>0.116543</td>\n",
       "      <td>0.081345</td>\n",
       "      <td>0.007039</td>\n",
       "      <td>0.068831</td>\n",
       "      <td>0.031678</td>\n",
       "      <td>0.032069</td>\n",
       "      <td>0.014470</td>\n",
       "      <td>0.013297</td>\n",
       "      <td>0.345327</td>\n",
       "      <td>0.019945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>CONJ</td>\n",
       "      <td>0.034292</td>\n",
       "      <td>0.112832</td>\n",
       "      <td>0.054757</td>\n",
       "      <td>0.056416</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.112832</td>\n",
       "      <td>0.348451</td>\n",
       "      <td>0.044248</td>\n",
       "      <td>0.063606</td>\n",
       "      <td>0.006084</td>\n",
       "      <td>0.157633</td>\n",
       "      <td>0.008850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>DET</td>\n",
       "      <td>0.018466</td>\n",
       "      <td>0.204687</td>\n",
       "      <td>0.009375</td>\n",
       "      <td>0.012642</td>\n",
       "      <td>0.000568</td>\n",
       "      <td>0.005824</td>\n",
       "      <td>0.640341</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>0.003409</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>0.039205</td>\n",
       "      <td>0.042614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>NOUN</td>\n",
       "      <td>0.238516</td>\n",
       "      <td>0.012830</td>\n",
       "      <td>0.176380</td>\n",
       "      <td>0.017734</td>\n",
       "      <td>0.042519</td>\n",
       "      <td>0.012830</td>\n",
       "      <td>0.262294</td>\n",
       "      <td>0.009327</td>\n",
       "      <td>0.004554</td>\n",
       "      <td>0.044183</td>\n",
       "      <td>0.149538</td>\n",
       "      <td>0.029295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>NUM</td>\n",
       "      <td>0.119099</td>\n",
       "      <td>0.034692</td>\n",
       "      <td>0.037196</td>\n",
       "      <td>0.002861</td>\n",
       "      <td>0.014664</td>\n",
       "      <td>0.003577</td>\n",
       "      <td>0.348712</td>\n",
       "      <td>0.183834</td>\n",
       "      <td>0.001788</td>\n",
       "      <td>0.028255</td>\n",
       "      <td>0.018956</td>\n",
       "      <td>0.206366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>PRON</td>\n",
       "      <td>0.040732</td>\n",
       "      <td>0.075515</td>\n",
       "      <td>0.022426</td>\n",
       "      <td>0.032952</td>\n",
       "      <td>0.005034</td>\n",
       "      <td>0.009153</td>\n",
       "      <td>0.208696</td>\n",
       "      <td>0.006865</td>\n",
       "      <td>0.008696</td>\n",
       "      <td>0.013730</td>\n",
       "      <td>0.484211</td>\n",
       "      <td>0.091991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>PRT</td>\n",
       "      <td>0.044688</td>\n",
       "      <td>0.088201</td>\n",
       "      <td>0.020384</td>\n",
       "      <td>0.010192</td>\n",
       "      <td>0.002352</td>\n",
       "      <td>0.103489</td>\n",
       "      <td>0.239514</td>\n",
       "      <td>0.058800</td>\n",
       "      <td>0.018032</td>\n",
       "      <td>0.001960</td>\n",
       "      <td>0.398667</td>\n",
       "      <td>0.013720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>VERB</td>\n",
       "      <td>0.036494</td>\n",
       "      <td>0.065340</td>\n",
       "      <td>0.091512</td>\n",
       "      <td>0.082850</td>\n",
       "      <td>0.005345</td>\n",
       "      <td>0.136393</td>\n",
       "      <td>0.105428</td>\n",
       "      <td>0.023961</td>\n",
       "      <td>0.035296</td>\n",
       "      <td>0.029859</td>\n",
       "      <td>0.168925</td>\n",
       "      <td>0.218597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>X</td>\n",
       "      <td>0.164003</td>\n",
       "      <td>0.016172</td>\n",
       "      <td>0.146880</td>\n",
       "      <td>0.025875</td>\n",
       "      <td>0.009323</td>\n",
       "      <td>0.056887</td>\n",
       "      <td>0.061073</td>\n",
       "      <td>0.002664</td>\n",
       "      <td>0.055936</td>\n",
       "      <td>0.183219</td>\n",
       "      <td>0.200152</td>\n",
       "      <td>0.077816</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             .       ADJ       ADP       ADV      CONJ       DET      NOUN  \\\n",
       ".     0.095412  0.044268  0.090792  0.052326  0.059847  0.174815  0.215322   \n",
       "ADJ   0.064415  0.065977  0.079641  0.003709  0.016787  0.005661  0.699395   \n",
       "ADP   0.039501  0.103338  0.016947  0.013507  0.000892  0.330912  0.322885   \n",
       "ADV   0.135315  0.134142  0.116543  0.081345  0.007039  0.068831  0.031678   \n",
       "CONJ  0.034292  0.112832  0.054757  0.056416  0.000000  0.112832  0.348451   \n",
       "DET   0.018466  0.204687  0.009375  0.012642  0.000568  0.005824  0.640341   \n",
       "NOUN  0.238516  0.012830  0.176380  0.017734  0.042519  0.012830  0.262294   \n",
       "NUM   0.119099  0.034692  0.037196  0.002861  0.014664  0.003577  0.348712   \n",
       "PRON  0.040732  0.075515  0.022426  0.032952  0.005034  0.009153  0.208696   \n",
       "PRT   0.044688  0.088201  0.020384  0.010192  0.002352  0.103489  0.239514   \n",
       "VERB  0.036494  0.065340  0.091512  0.082850  0.005345  0.136393  0.105428   \n",
       "X     0.164003  0.016172  0.146880  0.025875  0.009323  0.056887  0.061073   \n",
       "\n",
       "           NUM      PRON       PRT      VERB         X  \n",
       ".     0.078973  0.065757  0.002579  0.091759  0.028043  \n",
       "ADJ   0.020301  0.000781  0.011321  0.011517  0.020496  \n",
       "ADP   0.059760  0.069062  0.001656  0.008410  0.033129  \n",
       "ADV   0.032069  0.014470  0.013297  0.345327  0.019945  \n",
       "CONJ  0.044248  0.063606  0.006084  0.157633  0.008850  \n",
       "DET   0.022727  0.003409  0.000142  0.039205  0.042614  \n",
       "NOUN  0.009327  0.004554  0.044183  0.149538  0.029295  \n",
       "NUM   0.183834  0.001788  0.028255  0.018956  0.206366  \n",
       "PRON  0.006865  0.008696  0.013730  0.484211  0.091991  \n",
       "PRT   0.058800  0.018032  0.001960  0.398667  0.013720  \n",
       "VERB  0.023961  0.035296  0.029859  0.168925  0.218597  \n",
       "X     0.002664  0.055936  0.183219  0.200152  0.077816  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#check how many unqiue tag we have.\n",
    "tags = np.unique([st[1] for st in train_split])\n",
    "tag_len = len(tags)\n",
    "\n",
    "# creat the transition matrix.\n",
    "trans_matrix = np.zeros((tag_len, tag_len))\n",
    "\n",
    "for row in range(tag_len):\n",
    "    for col in range(tag_len):\n",
    "        trans_matrix[row][col] = transition(tags[row], tags[col])\n",
    "        \n",
    "#print out the matrix table\n",
    "matrix_table = pd.DataFrame(trans_matrix, index=tags, columns = tags)\n",
    "display(matrix_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Viterbi(words, tags):\n",
    "    seq = []\n",
    "    final_seq = []\n",
    "    for index, word in enumerate(words):\n",
    "        prob = [] \n",
    "        for tag in tags:\n",
    "            if index == 0:\n",
    "                tran_prob = matrix_table.loc['.', tag]  \n",
    "            else:\n",
    "                tran_prob = matrix_table.loc[seq[-1], tag]\n",
    "\n",
    "            emi_prob = Emission(word, tag)\n",
    "            final_prob = emi_prob * tran_prob  \n",
    "            \n",
    "            prob.append(final_prob)\n",
    "            \n",
    "        most_poss_index = prob.index(max(prob))\n",
    "        final_max = tags[most_poss_index] \n",
    "        seq.append(final_max)\n",
    "    \n",
    "    for i in range(len(seq)):\n",
    "        final_seq.append((words[i], seq[i]))\n",
    "        \n",
    "    return final_seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('I', 'PRON'), ('am', 'VERB'), ('so', 'ADV'), ('happy', 'ADJ'), ('to', 'PRT'), ('see', 'VERB'), ('you', 'PRON'), ('!', '.')]\n"
     ]
    }
   ],
   "source": [
    "random.seed(1)\n",
    "\n",
    "def check_accuracy(test_word, actual_data, tags):\n",
    "    test_num = len(test_word)\n",
    "    start = time.time()\n",
    "    predict = Viterbi(test_word, tags)\n",
    "    end = time.time()\n",
    "\n",
    "    print(\"Totsl time spent: %s\" % (end-start))\n",
    "\n",
    "    right = 0\n",
    "    for i in range(test_num):\n",
    "        if predict[i] == actual_data[i]:\n",
    "            right+=1\n",
    "    \n",
    "    return right/test_num*100\n",
    "    \n",
    "\n",
    "# select n random sentence, make actual data for checking, and testing \n",
    "# print(len(test_data))\n",
    "# for i in range(10):\n",
    "#     print(random.randint(1,len(test_data)))\n",
    "# test_subset = [test_data[random.randint(1,len(test_data))] for i in range(10)]\n",
    "\n",
    "# for i in range(1,10):\n",
    "#     actual_data = []\n",
    "#     test_word = []\n",
    "#     for sentence in test_subset[:i]:\n",
    "#         for st in sentence:\n",
    "#             actual_data.append(st)\n",
    "#             test_word.append(st[0])\n",
    "            \n",
    "#     print('Viterbi Algorithm Accuracy: ',check_accuracy(test_word, actual_data, tags))\n",
    "    \n",
    "    \n",
    "words = ['I', \"am\", \"so\", \"happy\", \"to\", \"see\", \"you\", \"!\"]\n",
    "print(Viterbi(words, tags))\n",
    "#print(check_accuracy(words, actual_data, tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am happy\n",
      "I : PRON\n",
      "am : VERB\n",
      "happy : ADJ\n"
     ]
    }
   ],
   "source": [
    "user_sentence = input()\n",
    "user_word = user_sentence.split(' ')\n",
    "viterbi = Viterbi(user_word, tags)\n",
    "for st in viterbi:\n",
    "    print(st[0],':', st[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
